{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EmotionDetectionModel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiwZkoi9cFVf",
        "outputId": "2717dad1-34d0-4abe-ff21-e1efcb7361a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A64xprUMdGw-",
        "outputId": "40b1742b-784d-4124-be24-6b0cf4dcbcb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%ls"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " EmotionDetectionDeep.h5     fer2013.bib   README\n",
            " EmotionDetectionDeep.json   fer2013.csv  \u001b[0m\u001b[01;34m'Untitled folder'\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H95nB1Lmdw7q",
        "outputId": "76ab1baa-8343-42f6-b54c-9235e3346c69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd 'drive'\n",
        "%ls "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'drive'\n",
            "/content/drive/My Drive/fer2013\n",
            " EmotionDetectionDeep.h5     fer2013.bib   README\n",
            " EmotionDetectionDeep.json   fer2013.csv  \u001b[0m\u001b[01;34m'Untitled folder'\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Wzbd6dgd2zq",
        "outputId": "0ac341ea-cedd-46ec-fcb4-e15717132c46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd 'My Drive'\n",
        "%ls"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'My Drive'\n",
            "/content/drive/My Drive/fer2013\n",
            " EmotionDetectionDeep.h5     fer2013.bib   README\n",
            " EmotionDetectionDeep.json   fer2013.csv  \u001b[0m\u001b[01;34m'Untitled folder'\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oXK-rwoeEaP",
        "outputId": "ec81266e-185d-4d5d-9604-946a06e6c802",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd fer2013"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'fer2013'\n",
            "/content/drive/My Drive/fer2013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMq8xKXWbv_T"
      },
      "source": [
        "'''importing all the necessary libraries'''\n",
        "import sys, os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "from keras.utils import np_utils\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paK_6u3bczTs"
      },
      "source": [
        "'''read the file in a pandas dataframe'''\n",
        "df=pd.read_csv('fer2013.csv')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sF6Bo4WVffwp"
      },
      "source": [
        "'''make lists for training and testing sets'''\n",
        "X_train,Y_train,X_test,Y_test=[],[],[],[]\n",
        "\n",
        "'''our initial pixel array has a type of object convert that to float32 and convert each row appending to training and testing lists to a numpy array'''\n",
        "for index, row in df.iterrows():\n",
        "    val=row['pixels'].split(\" \")\n",
        "    try:\n",
        "        if 'Training' in row['Usage']:\n",
        "           X_train.append(np.array(val,'float32'))\n",
        "           Y_train.append(row['emotion'])\n",
        "        elif 'PublicTest' in row['Usage']:\n",
        "           X_test.append(np.array(val,'float32'))\n",
        "           Y_test.append(row['emotion'])\n",
        "    except:\n",
        "        print(f\"error occured at index :{index} and row:{row}\")\n",
        "\n",
        "\n",
        "num_labels = 7\n",
        "batch_size = 64\n",
        "epochs = 30\n",
        "width, height = 48, 48\n",
        "\n",
        "'''convert the whole training and testing list into a numpy array'''\n",
        "X_train = np.array(X_train,'float32')\n",
        "Y_train = np.array(Y_train,'float32')\n",
        "X_test = np.array(X_test,'float32')\n",
        "Y_test = np.array(Y_test,'float32')\n",
        "\n",
        "'''categorical_crossentropy requires the data in categorical form'''\n",
        "Y_train=np_utils.to_categorical(Y_train, num_classes=num_labels)\n",
        "Y_test=np_utils.to_categorical(Y_test, num_classes=num_labels)\n",
        "\n",
        "'''Normalize the X inputs'''\n",
        "X_train -= np.mean(X_train, axis=0)\n",
        "X_train /= np.std(X_train, axis=0)\n",
        "\n",
        "X_test -= np.mean(X_test, axis=0)\n",
        "X_test /= np.std(X_test, axis=0)\n",
        "\n",
        "'''Convert the X inputs into required form for a Neural Network'''\n",
        "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ysSWnbWb9VF",
        "outputId": "98915362-bf46-4ee6-aec9-b05219f91f8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"X_train:{}\".format(X_train[0:2]))\n",
        "print(\"X_test:{}\".format(X_test[0:2]))\n",
        "print(\"Y_train:{}\".format(Y_train[0:2]))\n",
        "print(\"Y_test:{}\".format(X_test[0:2]))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train:[[[[-0.6098866 ]\n",
            "   [-0.4592209 ]\n",
            "   [-0.40325198]\n",
            "   ...\n",
            "   [-0.7694696 ]\n",
            "   [-0.90518403]\n",
            "   [-0.95160526]]\n",
            "\n",
            "  [[-0.66049284]\n",
            "   [-0.68162924]\n",
            "   [-0.694159  ]\n",
            "   ...\n",
            "   [-0.7112763 ]\n",
            "   [-0.7862608 ]\n",
            "   [-0.90819967]]\n",
            "\n",
            "  [[-0.83170736]\n",
            "   [-0.8952668 ]\n",
            "   [-0.73603356]\n",
            "   ...\n",
            "   [-0.7924775 ]\n",
            "   [-0.7261497 ]\n",
            "   [-0.8613453 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.33269772]\n",
            "   [-0.6514918 ]\n",
            "   [-0.93670547]\n",
            "   ...\n",
            "   [-0.5265123 ]\n",
            "   [-0.7377333 ]\n",
            "   [-0.9078971 ]]\n",
            "\n",
            "  [[-0.5099617 ]\n",
            "   [-0.43692893]\n",
            "   [-0.46537215]\n",
            "   ...\n",
            "   [-0.10019822]\n",
            "   [-0.5580577 ]\n",
            "   [-0.86989194]]\n",
            "\n",
            "  [[-0.5095401 ]\n",
            "   [-0.56317693]\n",
            "   [-0.3986179 ]\n",
            "   ...\n",
            "   [-0.08629682]\n",
            "   [-0.0573744 ]\n",
            "   [-0.41127437]]]\n",
            "\n",
            "\n",
            " [[[ 0.37236458]\n",
            "   [ 0.40461555]\n",
            "   [ 0.41102034]\n",
            "   ...\n",
            "   [ 0.19833209]\n",
            "   [ 0.2950228 ]\n",
            "   [ 0.01161678]]\n",
            "\n",
            "  [[ 0.3893324 ]\n",
            "   [ 0.4109821 ]\n",
            "   [ 0.45377484]\n",
            "   ...\n",
            "   [ 0.12469399]\n",
            "   [ 0.3214692 ]\n",
            "   [ 0.2319735 ]]\n",
            "\n",
            "  [[ 0.40903383]\n",
            "   [ 0.4540902 ]\n",
            "   [ 0.56116307]\n",
            "   ...\n",
            "   [-0.02652   ]\n",
            "   [ 0.11207935]\n",
            "   [ 0.35659403]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.8876818 ]\n",
            "   [ 0.9052011 ]\n",
            "   [ 0.06995171]\n",
            "   ...\n",
            "   [ 0.93530357]\n",
            "   [ 0.9149289 ]\n",
            "   [ 0.908479  ]]\n",
            "\n",
            "  [[ 0.8888102 ]\n",
            "   [ 0.8932825 ]\n",
            "   [ 1.0274421 ]\n",
            "   ...\n",
            "   [ 0.9468874 ]\n",
            "   [ 0.8766316 ]\n",
            "   [ 0.9213457 ]]\n",
            "\n",
            "  [[ 0.863705  ]\n",
            "   [ 0.8571527 ]\n",
            "   [ 0.8907631 ]\n",
            "   ...\n",
            "   [ 1.0387505 ]\n",
            "   [ 0.8913998 ]\n",
            "   [ 0.8866632 ]]]]\n",
            "X_test:[[[[ 1.6505896 ]\n",
            "   [ 1.7122597 ]\n",
            "   [ 1.774942  ]\n",
            "   ...\n",
            "   [-1.2007871 ]\n",
            "   [-1.4180579 ]\n",
            "   [ 0.5287383 ]]\n",
            "\n",
            "  [[ 1.6706394 ]\n",
            "   [ 1.735452  ]\n",
            "   [ 1.8093711 ]\n",
            "   ...\n",
            "   [-1.18421   ]\n",
            "   [-1.4165792 ]\n",
            "   [ 0.06540257]]\n",
            "\n",
            "  [[ 1.6902738 ]\n",
            "   [ 1.7594564 ]\n",
            "   [ 1.835705  ]\n",
            "   ...\n",
            "   [-1.0598068 ]\n",
            "   [-1.4072696 ]\n",
            "   [-0.02004949]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.65270513]\n",
            "   [-0.3880233 ]\n",
            "   [-0.21744046]\n",
            "   ...\n",
            "   [ 1.8131278 ]\n",
            "   [ 1.7565633 ]\n",
            "   [ 1.7378885 ]]\n",
            "\n",
            "  [[-0.43341777]\n",
            "   [-0.3116194 ]\n",
            "   [-0.3077701 ]\n",
            "   ...\n",
            "   [ 1.5599844 ]\n",
            "   [ 1.785993  ]\n",
            "   [ 1.7480594 ]]\n",
            "\n",
            "  [[-0.3203255 ]\n",
            "   [-0.33700454]\n",
            "   [-0.38944486]\n",
            "   ...\n",
            "   [-0.9225547 ]\n",
            "   [ 0.18117245]\n",
            "   [ 0.80417955]]]\n",
            "\n",
            "\n",
            " [[[ 0.45219082]\n",
            "   [ 0.84190166]\n",
            "   [ 1.0658671 ]\n",
            "   ...\n",
            "   [ 0.5731197 ]\n",
            "   [ 0.4906877 ]\n",
            "   [ 0.39366612]]\n",
            "\n",
            "  [[ 0.34311205]\n",
            "   [ 0.8348267 ]\n",
            "   [ 1.1059843 ]\n",
            "   ...\n",
            "   [ 0.6423406 ]\n",
            "   [ 0.5081616 ]\n",
            "   [ 0.40972537]]\n",
            "\n",
            "  [[ 0.2202261 ]\n",
            "   [ 0.7781215 ]\n",
            "   [ 1.0771161 ]\n",
            "   ...\n",
            "   [ 0.7152708 ]\n",
            "   [ 0.6148504 ]\n",
            "   [ 0.48470077]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-1.1313825 ]\n",
            "   [-1.1594504 ]\n",
            "   [-1.2110373 ]\n",
            "   ...\n",
            "   [ 0.8327548 ]\n",
            "   [ 0.7693058 ]\n",
            "   [ 0.7136794 ]]\n",
            "\n",
            "  [[-1.1253655 ]\n",
            "   [-1.2456722 ]\n",
            "   [-1.1977048 ]\n",
            "   ...\n",
            "   [ 0.80220306]\n",
            "   [ 0.72793555]\n",
            "   [ 0.66518474]]\n",
            "\n",
            "  [[-1.2258772 ]\n",
            "   [-1.2955414 ]\n",
            "   [-1.1746722 ]\n",
            "   ...\n",
            "   [ 0.73589116]\n",
            "   [ 0.6640275 ]\n",
            "   [ 0.5656745 ]]]]\n",
            "Y_train:[[1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]]\n",
            "Y_test:[[[[ 1.6505896 ]\n",
            "   [ 1.7122597 ]\n",
            "   [ 1.774942  ]\n",
            "   ...\n",
            "   [-1.2007871 ]\n",
            "   [-1.4180579 ]\n",
            "   [ 0.5287383 ]]\n",
            "\n",
            "  [[ 1.6706394 ]\n",
            "   [ 1.735452  ]\n",
            "   [ 1.8093711 ]\n",
            "   ...\n",
            "   [-1.18421   ]\n",
            "   [-1.4165792 ]\n",
            "   [ 0.06540257]]\n",
            "\n",
            "  [[ 1.6902738 ]\n",
            "   [ 1.7594564 ]\n",
            "   [ 1.835705  ]\n",
            "   ...\n",
            "   [-1.0598068 ]\n",
            "   [-1.4072696 ]\n",
            "   [-0.02004949]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.65270513]\n",
            "   [-0.3880233 ]\n",
            "   [-0.21744046]\n",
            "   ...\n",
            "   [ 1.8131278 ]\n",
            "   [ 1.7565633 ]\n",
            "   [ 1.7378885 ]]\n",
            "\n",
            "  [[-0.43341777]\n",
            "   [-0.3116194 ]\n",
            "   [-0.3077701 ]\n",
            "   ...\n",
            "   [ 1.5599844 ]\n",
            "   [ 1.785993  ]\n",
            "   [ 1.7480594 ]]\n",
            "\n",
            "  [[-0.3203255 ]\n",
            "   [-0.33700454]\n",
            "   [-0.38944486]\n",
            "   ...\n",
            "   [-0.9225547 ]\n",
            "   [ 0.18117245]\n",
            "   [ 0.80417955]]]\n",
            "\n",
            "\n",
            " [[[ 0.45219082]\n",
            "   [ 0.84190166]\n",
            "   [ 1.0658671 ]\n",
            "   ...\n",
            "   [ 0.5731197 ]\n",
            "   [ 0.4906877 ]\n",
            "   [ 0.39366612]]\n",
            "\n",
            "  [[ 0.34311205]\n",
            "   [ 0.8348267 ]\n",
            "   [ 1.1059843 ]\n",
            "   ...\n",
            "   [ 0.6423406 ]\n",
            "   [ 0.5081616 ]\n",
            "   [ 0.40972537]]\n",
            "\n",
            "  [[ 0.2202261 ]\n",
            "   [ 0.7781215 ]\n",
            "   [ 1.0771161 ]\n",
            "   ...\n",
            "   [ 0.7152708 ]\n",
            "   [ 0.6148504 ]\n",
            "   [ 0.48470077]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-1.1313825 ]\n",
            "   [-1.1594504 ]\n",
            "   [-1.2110373 ]\n",
            "   ...\n",
            "   [ 0.8327548 ]\n",
            "   [ 0.7693058 ]\n",
            "   [ 0.7136794 ]]\n",
            "\n",
            "  [[-1.1253655 ]\n",
            "   [-1.2456722 ]\n",
            "   [-1.1977048 ]\n",
            "   ...\n",
            "   [ 0.80220306]\n",
            "   [ 0.72793555]\n",
            "   [ 0.66518474]]\n",
            "\n",
            "  [[-1.2258772 ]\n",
            "   [-1.2955414 ]\n",
            "   [-1.1746722 ]\n",
            "   ...\n",
            "   [ 0.73589116]\n",
            "   [ 0.6640275 ]\n",
            "   [ 0.5656745 ]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FXvv8IYb0In",
        "outputId": "cf9e4dd7-473c-4f89-fd83-732e210848dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "'''Define the model architecture '''\n",
        "layers = [\n",
        "          Conv2D(filters=16, kernel_size=(3,3), strides=(1, 1), padding='same', activation='relu',input_shape=(width,height,1)),\n",
        "          BatchNormalization(),\n",
        "          MaxPooling2D(pool_size=(2,2),strides=(2,2)),\n",
        "          Conv2D(filters=32, kernel_size=(3,3), strides=(1, 1), padding='same', activation='relu'),\n",
        "          BatchNormalization(),\n",
        "          MaxPooling2D(pool_size=(2,2),strides=(2,2)),\n",
        "          Conv2D(filters=64, kernel_size=(3,3), strides=(1, 1), padding='same', activation='relu'),\n",
        "          BatchNormalization(),\n",
        "          MaxPooling2D(pool_size=(2,2),strides=(2,2)),\n",
        "          Conv2D(filters=128, kernel_size=(3,3), strides=(1, 1), padding='same', activation='relu'),\n",
        "          BatchNormalization(),\n",
        "          MaxPooling2D(pool_size=(2,2),strides=(2,2)),\n",
        "          Conv2D(filters=256, kernel_size=(3,3), strides=(1, 1), padding='same', activation='relu'),\n",
        "          BatchNormalization(),\n",
        "          MaxPooling2D(pool_size=(2,2),strides=(2,2)),\n",
        "          Flatten(),\n",
        "          Dense(128,activation='relu'),\n",
        "          Dense(64,activation='relu'),\n",
        "          Dense(7,activation='softmax') ]\n",
        "\n",
        "model = Sequential(layers)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "'''Compile the model'''\n",
        "model.compile(loss=categorical_crossentropy,\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "'''Fit the model'''\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, Y_test),\n",
        "          shuffle=True)\n",
        "\n",
        "\n",
        "'''Save the model weights into a h5 file'''\n",
        "save_json = model.to_json()\n",
        "with open('EmotionDetectionDeep.json','w') as json_file:\n",
        "    json_file.write(save_json )\n",
        "model.save('EmotionDetectionDeep.h5')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_15 (Conv2D)           (None, 48, 48, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 48, 48, 16)        64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 24, 24, 32)        4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 24, 24, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 12, 12, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 12, 12, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 6, 6, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 6, 6, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 3, 3, 256)         295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 3, 3, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 7)                 455       \n",
            "=================================================================\n",
            "Total params: 435,911\n",
            "Trainable params: 434,919\n",
            "Non-trainable params: 992\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "449/449 [==============================] - 3s 6ms/step - loss: 1.5468 - accuracy: 0.3956 - val_loss: 1.4040 - val_accuracy: 0.4734\n",
            "Epoch 2/30\n",
            "449/449 [==============================] - 3s 6ms/step - loss: 1.2571 - accuracy: 0.5183 - val_loss: 1.2848 - val_accuracy: 0.5063\n",
            "Epoch 3/30\n",
            "449/449 [==============================] - 3s 6ms/step - loss: 1.1095 - accuracy: 0.5794 - val_loss: 1.2218 - val_accuracy: 0.5417\n",
            "Epoch 4/30\n",
            "449/449 [==============================] - 3s 6ms/step - loss: 0.9978 - accuracy: 0.6253 - val_loss: 1.1851 - val_accuracy: 0.5559\n",
            "Epoch 5/30\n",
            "449/449 [==============================] - 3s 6ms/step - loss: 0.8724 - accuracy: 0.6712 - val_loss: 1.2182 - val_accuracy: 0.5628\n",
            "Epoch 6/30\n",
            "449/449 [==============================] - 3s 6ms/step - loss: 0.7485 - accuracy: 0.7258 - val_loss: 1.3481 - val_accuracy: 0.5467\n",
            "Epoch 7/30\n",
            "449/449 [==============================] - 3s 6ms/step - loss: 0.6227 - accuracy: 0.7730 - val_loss: 1.4554 - val_accuracy: 0.5626\n",
            "Epoch 8/30\n",
            "449/449 [==============================] - 3s 6ms/step - loss: 0.4969 - accuracy: 0.8207 - val_loss: 1.5456 - val_accuracy: 0.5475\n",
            "Epoch 9/30\n",
            "449/449 [==============================] - 3s 6ms/step - loss: 0.3831 - accuracy: 0.8612 - val_loss: 1.7050 - val_accuracy: 0.5430\n",
            "Epoch 10/30\n",
            "449/449 [==============================] - 3s 6ms/step - loss: 0.3141 - accuracy: 0.8870 - val_loss: 1.7847 - val_accuracy: 0.5561\n",
            "Epoch 11/30\n",
            "449/449 [==============================] - 3s 6ms/step - loss: 0.2394 - accuracy: 0.9168 - val_loss: 1.8396 - val_accuracy: 0.5687\n",
            "Epoch 12/30\n",
            "449/449 [==============================] - 3s 6ms/step - loss: 0.2034 - accuracy: 0.9286 - val_loss: 2.0891 - val_accuracy: 0.5704\n",
            "Epoch 13/30\n",
            "449/449 [==============================] - 3s 6ms/step - loss: 0.1732 - accuracy: 0.9409 - val_loss: 2.1987 - val_accuracy: 0.5653\n",
            "Epoch 14/30\n",
            "449/449 [==============================] - 3s 6ms/step - loss: 0.1612 - accuracy: 0.9434 - val_loss: 2.2593 - val_accuracy: 0.5639\n",
            "Epoch 15/30\n",
            "449/449 [==============================] - 3s 6ms/step - loss: 0.1404 - accuracy: 0.9522 - val_loss: 2.3660 - val_accuracy: 0.5662\n",
            "Epoch 16/30\n",
            "449/449 [==============================] - 3s 6ms/step - loss: 0.1266 - accuracy: 0.9551 - val_loss: 2.3788 - val_accuracy: 0.5706\n",
            "Epoch 17/30\n",
            "449/449 [==============================] - 3s 6ms/step - loss: 0.1217 - accuracy: 0.9576 - val_loss: 2.5390 - val_accuracy: 0.5712\n",
            "Epoch 18/30\n",
            "449/449 [==============================] - 3s 6ms/step - loss: 0.1035 - accuracy: 0.9647 - val_loss: 2.6723 - val_accuracy: 0.5670\n",
            "Epoch 19/30\n",
            "449/449 [==============================] - 3s 6ms/step - loss: 0.1143 - accuracy: 0.9615 - val_loss: 2.5912 - val_accuracy: 0.5508\n",
            "Epoch 20/30\n",
            "449/449 [==============================] - 3s 6ms/step - loss: 0.1031 - accuracy: 0.9652 - val_loss: 2.4891 - val_accuracy: 0.5759\n",
            "Epoch 21/30\n",
            "449/449 [==============================] - 3s 6ms/step - loss: 0.1024 - accuracy: 0.9654 - val_loss: 2.6045 - val_accuracy: 0.5720\n",
            "Epoch 22/30\n",
            "449/449 [==============================] - 3s 6ms/step - loss: 0.0953 - accuracy: 0.9672 - val_loss: 2.5850 - val_accuracy: 0.5506\n",
            "Epoch 23/30\n",
            "449/449 [==============================] - 3s 6ms/step - loss: 0.0918 - accuracy: 0.9684 - val_loss: 2.6824 - val_accuracy: 0.5715\n",
            "Epoch 24/30\n",
            "449/449 [==============================] - 3s 6ms/step - loss: 0.0890 - accuracy: 0.9701 - val_loss: 2.6549 - val_accuracy: 0.5665\n",
            "Epoch 25/30\n",
            "449/449 [==============================] - 3s 6ms/step - loss: 0.0755 - accuracy: 0.9750 - val_loss: 2.9387 - val_accuracy: 0.5595\n",
            "Epoch 26/30\n",
            "449/449 [==============================] - 3s 6ms/step - loss: 0.0813 - accuracy: 0.9722 - val_loss: 2.9290 - val_accuracy: 0.5651\n",
            "Epoch 27/30\n",
            "449/449 [==============================] - 3s 6ms/step - loss: 0.0739 - accuracy: 0.9747 - val_loss: 2.8434 - val_accuracy: 0.5715\n",
            "Epoch 28/30\n",
            "449/449 [==============================] - 3s 6ms/step - loss: 0.0797 - accuracy: 0.9718 - val_loss: 2.7985 - val_accuracy: 0.5759\n",
            "Epoch 29/30\n",
            "449/449 [==============================] - 3s 6ms/step - loss: 0.0743 - accuracy: 0.9746 - val_loss: 2.7941 - val_accuracy: 0.5698\n",
            "Epoch 30/30\n",
            "449/449 [==============================] - 3s 6ms/step - loss: 0.0733 - accuracy: 0.9752 - val_loss: 2.7817 - val_accuracy: 0.5734\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}